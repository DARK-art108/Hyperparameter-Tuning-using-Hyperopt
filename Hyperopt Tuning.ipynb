{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7vZ0_z7mzn3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Importing sklearn packages!!\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris,load_diabetes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fsc--Wi9nUKh"
   },
   "source": [
    "##**Importing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8_kqfFtnLX4"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2odZ-qCqQ-Q"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQ-rIqhkpyPU"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.10,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rt5ux1Z1qvSW"
   },
   "source": [
    "## Training model on RFC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "JlSRDj0Kqty4",
    "outputId": "c40af37d-e005-42e2-abd3-9f81a931fbbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGYyLfxvw_vJ"
   },
   "source": [
    "## Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "4K5fjcCtwXUA",
    "outputId": "d01e6fb7-aff0-4480-eadf-1a7952b018ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  6]\n",
      " [10 16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7922077922077922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2bhXyh_0_v_"
   },
   "source": [
    "## Applying K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MNaSHJu40_A8",
    "outputId": "dc32fa77-165d-4deb-a38d-eb6bdb02859b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracies.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYQXDMlo3JRC"
   },
   "source": [
    "## Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "53WanDzc2_fO",
    "outputId": "83c68e75-04bd-40ce-a838-e706bced1b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 420 candidates, totalling 4200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1316 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2448 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3908 tasks      | elapsed:   49.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 77.43 %\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_split': 7, 'n_estimators': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4200 out of 4200 | elapsed:   53.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators':[10,20,30,40,50,60,70],\n",
    "               'max_depth': [3,4,5,7],\n",
    "               'criterion':['entropy'],\n",
    "               'min_samples_split':[5,4,6,7,8],\n",
    "               'max_features':['auto', 'sqrt', 'log2']\n",
    "               }]\n",
    "grid_search = GridSearchCV(estimator= classifier,\n",
    "                           param_grid= parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1,\n",
    "                           verbose=2,\n",
    "                           cv = 10)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYKLGmJczNJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /opt/conda/envs/fastai/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: future in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.18.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (4.43.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/fastai/lib/python3.7/site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /opt/conda/envs/fastai/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (4.43.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (1.14.0)\n",
      "Requirement already satisfied: future in /opt/conda/envs/fastai/lib/python3.7/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/fastai/lib/python3.7/site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Model Using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'criterion' : hp.choice('criterion', ['entropy','gini']),\n",
    "         'max_depth' : hp.quniform('max_depth',10,1200,10),\n",
    "         'max_features' : hp.choice('max_features',['auto','sqrt','log2',None]),\n",
    "         'min_samples_leaf' : hp.uniform('min_samples_leaf',0,0.5),\n",
    "         'min_samples_split' : hp.uniform('min_samples_split',0,1),\n",
    "         'n_estimators': hp.choice('n_estimators',[10,50,350,550,750,1200,1300,1500])\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': <hyperopt.pyll.base.Apply at 0x7fe83307e990>,\n",
       " 'max_depth': <hyperopt.pyll.base.Apply at 0x7fe833019cd0>,\n",
       " 'max_features': <hyperopt.pyll.base.Apply at 0x7fe833019f90>,\n",
       " 'min_samples_leaf': <hyperopt.pyll.base.Apply at 0x7fe8334ba8d0>,\n",
       " 'min_samples_split': <hyperopt.pyll.base.Apply at 0x7fe83a7475d0>,\n",
       " 'n_estimators': <hyperopt.pyll.base.Apply at 0x7fe83316af90>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x7fe833019cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    model = RandomForestClassifier( criterion = space['criterion'],\n",
    "                                    max_depth = space['max_depth'],\n",
    "                                    max_features = space['max_features'],\n",
    "                                    min_samples_leaf = space['min_samples_leaf'],\n",
    "                                    min_samples_split = space['min_samples_split'],\n",
    "                                    n_estimators = space['n_estimators']\n",
    "    )\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_train,y_train,cv=10).mean()\n",
    "    return {'loss' : -accuracy , 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [15:33<00:00, 11.66s/trial, best loss: -0.7569358178053831]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 0,\n",
       " 'max_depth': 1140.0,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 0.09415105426583024,\n",
       " 'min_samples_split': 0.2254281615429092,\n",
       " 'n_estimators': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "trials = Trials()\n",
    "best = fmin(fn = objective,\n",
    "            space=space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals=80,\n",
    "            trials=trials\n",
    "           )\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy\n",
      "None\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "crit = {0: 'entropy', 1: 'gini'}\n",
    "feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
    "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200,5:1300,6:1500}\n",
    "\n",
    "\n",
    "print(crit[best['criterion']])\n",
    "print(feat[best['max_features']])\n",
    "print(est[best['n_estimators']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  5]\n",
      " [ 9 17]]\n",
      "0.8181818181818182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        51\n",
      "           1       0.77      0.65      0.71        26\n",
      "\n",
      "    accuracy                           0.82        77\n",
      "   macro avg       0.80      0.78      0.79        77\n",
      "weighted avg       0.81      0.82      0.81        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], max_depth = best['max_depth'], \n",
    "                                       max_features = feat[best['max_features']], \n",
    "                                       min_samples_leaf = best['min_samples_leaf'], \n",
    "                                       min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']]).fit(X_train,y_train)\n",
    "predictionforest = trainedforest.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictionforest))\n",
    "print(accuracy_score(y_test,predictionforest))\n",
    "print(classification_report(y_test,predictionforest))\n",
    "acc5 = accuracy_score(y_test,predictionforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Random Forest Classifier with GridSearchCV Optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
